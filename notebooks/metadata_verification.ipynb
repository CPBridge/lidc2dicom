{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "The purpose of this notebook is to provide an example of how standard DICOM objects containing annotations and evaluations of the nodules for the TCIA [LIDC-IDRI](https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI) collection, as presented in the following article, can be used from Python.\n",
    "\n",
    "> Fedorov A, Hancock M, Clunie D, Brochhausen M, Bona J, Kirby J, Freymann J, Pieper S, Aerts H, Kikinis R, Prior F. 2018. Standardized representation of the LIDC annotations using DICOM. PeerJ Preprints 6:e27378v1 https://doi.org/10.7287/peerj.preprints.27378\n",
    "\n",
    "Another goal of this notebook is to validate the accuracy of the conversion from the `pylidc` representation.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook assumes you have the following locally on your computer:\n",
    "* Images from the TCIA LIDC-IDRI collection, see download instructions here: https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI\n",
    "* DICOM Segmentations and Structured Reporting objects (at the time of writing this, those are located separately from the images), see download instructions here: https://wiki.cancerimagingarchive.net/display/DOI/Standardized+representation+of+the+TCIA+LIDC-IDRI+annotations+using+DICOM\n",
    "\n",
    "\n",
    "## Conversion consistency verification approach\n",
    "\n",
    "Conversion verification is done by confirming that:\n",
    "* each of the nodules larger than 3 mm, as queried from `pylidc`, is also encoded in DICOM;\n",
    "* there is only one DICOM SEG and one DICOM SR object corresponding to a single annotation of a nodule in the DICOM dataset;\n",
    "* quantitative and qualitative assessment values are consistent between the two representations.\n",
    "\n",
    "Verification consists of evaluating two components of the dataset metadata (evaluations, measurements, referenced images) and pixel data (voxels labeled as belonging to a certain nodule).\n",
    "\n",
    "In order to support this verification, the data first needs to be prepared for consuming it from python. Although there can be various ways to do this, our approach will utilize the following steps:\n",
    "1. DICOM files are first organized using [dicomsort](https://github.com/pieper/dicomsort):\n",
    "\n",
    "`python dicomsort.py <location of DICOM images, SEG and SR files> \\\n",
    "  <directory to store sorted files>/%PatientID/%StudyInstanceUID/%SeriesInstanceUID-%SeriesNumber-%Modality/%SOPInstanceUID.dcm`\n",
    "\n",
    "2. Extract DICOM metadata into tabular form using [dcm2tables](https://github.com/QIICR/dcm2tables). The result is a set of tables that are defined by [this schema](https://app.quickdatabasediagrams.com/#/d/K6UbDf).\n",
    "\n",
    "`python tabulate.py -s schema.qdbd -d <directory with the sorted files> -o <directory to store metadata tables>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylidc as pl\n",
    "import pandas as pd\n",
    "import os, json\n",
    "\n",
    "DICOM_PATH = \"/Users/fedorov/Temp/LIDC_conversion2-sorted\"\n",
    "DCMTABLES_PATH = \"/Users/fedorov/Temp/LIDC_conversion2-tables\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read DICOM metadata tables\n",
    "tablesNames = [\n",
    "               'CompositeContext', # one per DICOM file, attributes that are available in every DICOM object\n",
    "    \n",
    "               'References',       # when applicable, references to related DICOM objects in the derived datasets\n",
    "    \n",
    "               'CT', 'SEG','SR',     # modality-specific attributes\n",
    "    \n",
    "               'SEG_Segments','SEG_SegmentFrames',  # attributes specific to DICOM Segmentations; each Segmentation\n",
    "                                                    # object contains one or more segment, and each segment contains\n",
    "                                                    # one or more frame (i.e., \"slice\") with the labeled pixels\n",
    "    \n",
    "               'SR1500_Measurements','SR1500_MeasurementGroups', # attributes specific to DICOM Structured Reports (SR)\n",
    "               'SR1500_QualitativeEvaluations',     # qualitative assessments\n",
    "    \n",
    "               'Instance2File'                      # pointer from the DICOM SOPInstanceUID to the file on the filesystem\n",
    "              ]\n",
    "tables = {}\n",
    "for t in tablesNames:\n",
    "    tables[t]=pd.read_csv(os.path.join(DCMTABLES_PATH,t+'.tsv'), sep='\\t', dtype=str, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionaries\n",
    "    \n",
    "conceptsDictionary = {}\n",
    "valuesDictionary = {}\n",
    "with open(\"../concepts_dict.json\") as cf:\n",
    "  conceptsDictionary = json.load(cf)\n",
    "with open(\"../values_dict.json\") as vf:\n",
    "  valuesDictionary = json.load(vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIDC-IDRI-0510\n",
      "Skipping knowingly faulty item\n",
      " Invalid attribute: internalStructure: 5 Nodule 8 - Annotation 1708\n",
      "  Failed to find quantitative assessment for Internal structure in DICOM representation\n"
     ]
    }
   ],
   "source": [
    "subjectsToVerify = [(\"LIDC-IDRI-%04i\" % i) for i in range(510,511)]\n",
    "\n",
    "# iterate over data, confirm existence of data, \n",
    "# one SEG and one SR per annotation, and consistency of numeric\n",
    "# and qualitative assessment values between pylidc and DICOM representation\n",
    "from decimal import *\n",
    "epsilon = 1e-2\n",
    "\n",
    "def compareNumbers(v1, v2):\n",
    "  assert (abs(v1-v2) < epsilon), \"Comparison threshold exceeded: %f vs %f!\" % (v1, v2) \n",
    "\n",
    "def compareStrings(s1, s2):\n",
    "  assert (s1 == s2), \"Comparison strings failed: %s vs %s!\" % (s1, s2) \n",
    "\n",
    "def compareCodes(c1, c2):\n",
    "  assert (c1[\"CodeValue\"] == c2[\"CodeValue\"]), \"CodeValue mismatch\"\n",
    "  assert (c1[\"CodeMeaning\"] == c2[\"CodeMeaning\"]), \"CodeMeaning mismatch\"\n",
    "  assert (c1[\"CodingSchemeDesignator\"] == c2[\"CodingSchemeDesignator\"]), \"CodingSchemeDesignator mismatch\"\n",
    "\n",
    "for s in subjectsToVerify:\n",
    "  print(s)\n",
    "  scans = pl.query(pl.Scan).filter(pl.Scan.patient_id == s)\n",
    "  for scan in scans:\n",
    "    studyUID = scan.study_instance_uid\n",
    "    seriesUID = scan.series_instance_uid\n",
    "    seriesDir = os.path.join(DICOM_PATH,s,studyUID,seriesUID)\n",
    "    \n",
    "    referencesSubset = tables[\"References\"][tables[\"References\"][\"ReferencedSeriesInstanceUID\"] == seriesUID]\n",
    "    referencingUIDs = pd.unique(referencesSubset[\"SOPInstanceUID\"])\n",
    "    thoseReferenceSeries = tables[\"CompositeContext\"][tables[\"CompositeContext\"][\"SOPInstanceUID\"].isin(referencingUIDs)]\n",
    "    \n",
    "    segmentations = thoseReferenceSeries[thoseReferenceSeries[\"Modality\"]==\"SEG\"]\n",
    "    segmentsSubset = tables[\"SEG_Segments\"][tables[\"SEG_Segments\"][\"SOPInstanceUID\"].isin(referencingUIDs)]\n",
    "    segments = pd.merge(segmentsSubset, segmentations, on=[\"SOPInstanceUID\"])\n",
    "        \n",
    "    #print(segments[\"SegmentLabel\"])\n",
    "    \n",
    "    for nCount,nodule in enumerate(scan.cluster_annotations()):\n",
    "      for aCount,a in enumerate(nodule):\n",
    "        \n",
    "        # this is the convention used to name segments (SegmentDescription and SegmentLabel)\n",
    "        segmentLabel = \"Nodule \"+str(nCount+1) +\" - Annotation \" + a._nodule_id\n",
    "        # Find corresponding segment:\n",
    "        #  1. find SEGs that reference the SeriesInstanceUID of the CT annotated\n",
    "        #  2. find the specific SEG using SegmentLabel\n",
    "        #  3. if there are multiple annotations that have the same ID, we are screwed\n",
    "        segment = segments[segments[\"SegmentLabel\"] == segmentLabel]\n",
    "        assert (segment.shape[0] == 1), \"More than one matching segment: %i!\" % segment.shape[0]\n",
    "        #print(str(segment[\"SOPInstanceUID\"].values))\n",
    "        \n",
    "        segmentationInstanceUID = segment[\"SOPInstanceUID\"].values[0]\n",
    "        \n",
    "        # now get measurement groups that correspond to those Structured Reports instances\n",
    "        # For the specific dataset, we know there is a single measurement group per segment,\n",
    "        #  and we also know there is a single segment per segmentation, so this makes life easier\n",
    "        measurementGroups = tables[\"SR1500_MeasurementGroups\"][tables[\"SR1500_MeasurementGroups\"][\"segmentationSOPInstanceUID\"] == segmentationInstanceUID]\n",
    "        assert (measurementGroups.shape[0] == 1), \"Not one measurement group per segment: %i!\" % measurementGroupsSubset.shape[0]\n",
    "        structuredReportUID = measurementGroups[\"SOPInstanceUID\"].values[0]\n",
    "        \n",
    "        qualEval = tables[\"SR1500_QualitativeEvaluations\"][tables[\"SR1500_QualitativeEvaluations\"][\"SOPInstanceUID\"] == structuredReportUID]\n",
    "        quantEval = tables[\"SR1500_Measurements\"][tables[\"SR1500_Measurements\"][\"SOPInstanceUID\"] == structuredReportUID]        \n",
    "        \n",
    "        # check quantitative measurements\n",
    "        assert (len(quantEval[quantEval[\"quantity_CodeMeaning\"]==\"Volume\"][\"value\"].values) == 1), \"Number of measurements is not one!\"\n",
    "        assert (len(quantEval[quantEval[\"quantity_CodeMeaning\"]==\"Diameter\"][\"value\"].values) == 1), \"Number of measurements is not one!\"\n",
    "        assert (len(quantEval[quantEval[\"quantity_CodeMeaning\"]==\"Surface area of mesh\"][\"value\"].values) == 1), \"Number of measurements is not one!\"\n",
    "\n",
    "        dcmVolume = quantEval[quantEval[\"quantity_CodeMeaning\"]==\"Volume\"][\"value\"].values[0]\n",
    "        dcmDiameter = quantEval[quantEval[\"quantity_CodeMeaning\"]==\"Diameter\"][\"value\"].values[0]\n",
    "        dcmSurface = quantEval[quantEval[\"quantity_CodeMeaning\"]==\"Surface area of mesh\"][\"value\"].values[0]\n",
    "        \n",
    "        compareStrings(dcmVolume,  (\"%E\" % Decimal(a.volume)))\n",
    "        compareStrings(dcmDiameter, (\"%E\" % Decimal(a.diameter)))\n",
    "        compareStrings(dcmSurface, (\"%E\" % Decimal(a.surface_area)))\n",
    "            \n",
    "        dcmStr = quantEval[quantEval[\"quantity_CodeMeaning\"]==\"Volume\"][\"value\"].values[0]\n",
    "        \n",
    "        # check code values\n",
    "        for attribute in conceptsDictionary.keys():\n",
    "          aItem = {}\n",
    "\n",
    "          if attribute == \"internalStructure\" and segmentLabel == \"Nodule 8 - Annotation 1708\" and s == \"LIDC-IDRI-0510\":\n",
    "            #print(\"  Skipping knowingly faulty item\")\n",
    "            continue\n",
    "        \n",
    "          try:\n",
    "            aItem[\"conceptCode\"] = conceptsDictionary[attribute]\n",
    "            aItem[\"conceptValue\"] = valuesDictionary[attribute][str(getattr(a, attribute))]\n",
    "          \n",
    "          except KeyError:            \n",
    "            print(\" Invalid attribute: \"+attribute+': '+str(getattr(a, attribute))+\" \"+segmentLabel)\n",
    "            \n",
    "          if qualEval[qualEval[\"conceptCode_CodeMeaning\"]==aItem[\"conceptCode\"][\"CodeMeaning\"]].shape[0] != 1:\n",
    "            print(\"  Failed to find quantitative assessment for %s in DICOM representation\" % aItem[\"conceptCode\"][\"CodeMeaning\"])\n",
    "            continue\n",
    "\n",
    "          #print(qualEval[\"conceptValue_CodeMeaning\"])\n",
    "          dcmItem = qualEval[qualEval[\"conceptCode_CodeMeaning\"]==aItem[\"conceptCode\"][\"CodeMeaning\"]]\n",
    "          compareCodes(aItem[\"conceptValue\"], {\"CodeValue\": dcmItem[\"conceptValue_CodeValue\"].values[0], \\\n",
    "                                               \"CodeMeaning\": dcmItem[\"conceptValue_CodeMeaning\"].values[0], \\\n",
    "                                               \"CodingSchemeDesignator\": dcmItem[\"conceptValue_CodingSchemeDesignator\"].values[0]})\n",
    "        \n",
    "#      break\n",
    "#    break\n",
    "#  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
